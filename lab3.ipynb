{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3 Redes neuronales profundas\n",
    "#### Orlando Cabrera 19943\n",
    "#### José Hurtarte 19707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josej\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:00,  2.28 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.77 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.23 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.23 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.23 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:02<00:00,  1.59 file/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:02<00:00,  3.96 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.58 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to ~\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datos_mnist, info_mnist = tfds.load(name='mnist',\n",
    "                                    shuffle_files = False,\n",
    "                                    with_info=True, \n",
    "                                    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entreno_mnist, prueba_mnist = datos_mnist['train'], datos_mnist['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_validacion = 0.1 * info_mnist.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_validacion = tf.cast(num_obs_validacion, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_prueba = info_mnist.splits['test'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_prueba = tf.cast(num_obs_prueba, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(imagen, etiqueta):\n",
    "    imagen = tf.cast(imagen, tf.float32)\n",
    "    imagen /= 255.\n",
    "    return imagen, etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento_y_validacion_normalizados = entreno_mnist.map(normalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba = prueba_mnist.map(normalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento_y_validacion_barajeados = datos_entrenamiento_y_validacion_normalizados.shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_validacion = datos_entrenamiento_y_validacion_barajeados.take(num_obs_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entreno = datos_entrenamiento_y_validacion_barajeados.skip(num_obs_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANIO_TANDA = 100\n",
    "\n",
    "datos_entreno = datos_entreno.batch(TAMANIO_TANDA)\n",
    "\n",
    "datos_validacion = datos_validacion.batch(num_obs_validacion)\n",
    "\n",
    "datos_prueba = datos_prueba.batch(num_obs_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_validacion, metas_validacion = next(iter(datos_validacion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. El ancho (tamaño de la capa escondida) del algoritmo. Intenten con un tamaño de 200.  ¿Cómo cambia la precisión de validación del modelo?  ¿Cuánto  tiempo se tardó el algoritmo en entrenar?  ¿Puede encontrar un tamaño de  capa escondida que funcione mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 200\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 2s - loss: 0.2724 - accuracy: 0.9213 - val_loss: 0.1249 - val_accuracy: 0.9610 - 2s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1052 - accuracy: 0.9680 - val_loss: 0.0808 - val_accuracy: 0.9753 - 2s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.0702 - accuracy: 0.9785 - val_loss: 0.0636 - val_accuracy: 0.9813 - 2s/epoch - 3ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 2s - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0513 - val_accuracy: 0.9837 - 2s/epoch - 3ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 2s - loss: 0.0411 - accuracy: 0.9873 - val_loss: 0.0404 - val_accuracy: 0.9860 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d60f508fd0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "modelo.fit(datos_entreno, \n",
    "          epochs = 5, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presición de validación 0.9860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0715 - accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida de prueba: 0.07. Precisión de prueba: 97.73%\n"
     ]
    }
   ],
   "source": [
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo bastante interesante es que a pesar de que fueran solo 2 capas escondidas y al aumentarle el numero de perceptrones por cada una de estas capas escondidas aumentó la presición de la validación de 0.9852 a 0.9860 además este siempre aumentó, por lo que a pesar del aumento de perceptrones no se observa overfit. Además hay una leve mejora en la presición de prueba del 96.69% al 97.73% por lo que podemos observar un leve aumento con respecto a las 50 neuronas por capa en el modelo inicial, además obtuvo un tiempo de ejecución de la creación del modelo de 8.6 segundos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. La profundidad del algoritmo.  Agreguen una capa escondida más al algoritmo. Este es un ejercicio extremadamente importante!  ¿Cómo cambia la precisión de validación?  ¿Qué hay del tiempo que se tarda en ejecutar?   Pista:  deben tener cuidado con las formas de los pesos y los sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 50\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 3a capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 2s - loss: 0.4086 - accuracy: 0.8794 - val_loss: 0.1970 - val_accuracy: 0.9430 - 2s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 1s - loss: 0.1695 - accuracy: 0.9493 - val_loss: 0.1321 - val_accuracy: 0.9597 - 1s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 1s - loss: 0.1293 - accuracy: 0.9610 - val_loss: 0.1167 - val_accuracy: 0.9643 - 1s/epoch - 3ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 1s - loss: 0.1064 - accuracy: 0.9681 - val_loss: 0.0939 - val_accuracy: 0.9728 - 1s/epoch - 3ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 1s - loss: 0.0912 - accuracy: 0.9724 - val_loss: 0.0879 - val_accuracy: 0.9732 - 1s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d611d688e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = 5, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presición de validación 0.9732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1108 - accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida de prueba: 0.11. Precisión de prueba: 96.72%\n"
     ]
    }
   ],
   "source": [
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo que podemos mencionar de esta red es que hay un consenso que nos dice que si tenemos una red que en total tiene más de 3 capas, se suele considerar de deep learning y cuando tiene menos se considera shallow learning. Debido a esto al aumentar capas en las redes neuronales se suele mejorar la comprensión de problemas complejos. Sin embargo en este caso pudimos observar que la presición de validación es de 0.9732 lo cual no mejora la presición de validación original lo cual también no es eficiente ya que generando mayor trabajo computacional genera resultados sub optimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. El ancho y la profundidad del algoritmo.  Agregue cuantas capas sean necesarias para llegar a 5 capas escondidas.  Es más, ajusten el ancho del algoritmo conforme lo encuentre más conveniente.  ¿Cómo cambia la precisiónde validación? ¿Qué hay del tiempo de ejecución?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según muchos estandares, no hay una forma exacta de definir cuales son las capas y cantidad de perceptrones optimas en cada una de las capas. Hay gente que recomienda utilizar solo 1 capa oculta con la media de la entrada y la salida o gente que recomienda que el tamaño de las capas escondidas sea 2/3 de la capa de entrada mas el tamaño de la capa de salida. Sin embargo según el siguiente artículo https://www.linkedin.com/pulse/choosing-number-hidden-layers-neurons-neural-networks-sachdev/, se suele recomendar seguir el tamaño de entrada de la red neuronal por el tamaño de salida de la red neuronal y tomar la raiz cuadrada de este numero calculado cuando deseamos utilizar una red con multiples capas escondidas. Por lo que este número en nuestro caso sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((78*78*10)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que siguiendo las directrices anteriores se generó el siguiente modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 246\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 3era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 4ta capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 5ta capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 3s - loss: 0.2579 - accuracy: 0.9217 - val_loss: 0.1341 - val_accuracy: 0.9597 - 3s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1047 - accuracy: 0.9676 - val_loss: 0.0783 - val_accuracy: 0.9767 - 2s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.0740 - accuracy: 0.9772 - val_loss: 0.0668 - val_accuracy: 0.9800 - 2s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 2s - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.0722 - val_accuracy: 0.9783 - 2s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 2s - loss: 0.0521 - accuracy: 0.9839 - val_loss: 0.0597 - val_accuracy: 0.9830 - 2s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d6108826d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos_entreno, \n",
    "          epochs = 5, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presición de validación 0.9830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0945 - accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida de prueba: 0.09. Precisión de prueba: 97.60%\n"
     ]
    }
   ],
   "source": [
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que este modelo nos da una presición de validación del 0.9830 por lo que podemos decir que mejora con respecto a la presición de validación inicial del 0.9717 sin embargo esta se vuelve suboptima ya que al observar con las 2 capas ocultas de 200 perceptrones cada una en el inciso 1 nos da 97.73% de presición de prueba, y también la presición de validación es menor a la del inciso 1. Por eso a pesar de que tome valores bastante buenos entre los modelos probados es una solución suboptima. Sin embargo es una buena forma de generalizar caracteristicas de la red neuronal obteniendo buenos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experimenten con las funciones de activación.  Intenten aplicar una transformación sigmoidal a ambas capas.  La activación sigmoidal se obtiene escribiendo “sigmoid”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 50\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='sigmoid'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='sigmoid'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 2s - loss: 0.9933 - accuracy: 0.7845 - val_loss: 0.4197 - val_accuracy: 0.8953 - 2s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 1s - loss: 0.3321 - accuracy: 0.9118 - val_loss: 0.2699 - val_accuracy: 0.9230 - 1s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 1s - loss: 0.2436 - accuracy: 0.9312 - val_loss: 0.2156 - val_accuracy: 0.9405 - 1s/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 1s - loss: 0.1994 - accuracy: 0.9432 - val_loss: 0.1764 - val_accuracy: 0.9513 - 1s/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 1s - loss: 0.1696 - accuracy: 0.9519 - val_loss: 0.1530 - val_accuracy: 0.9577 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d6113fd640>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "modelo.fit(datos_entreno, \n",
    "          epochs = 5, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presición de validación 0.9577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1652 - accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida de prueba: 0.17. Precisión de prueba: 95.05%\n"
     ]
    }
   ],
   "source": [
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir de esta que tanto la presición de prueba (95.05%) y la de la validación (0.9577) con función de activación sigmoidal tiene resultados más bajos de estos campos que la que únicamente utiliza función de activación de unidades linealmente rectificadas en las capas escondidas. Por lo que podemos decir que utilizando función sigmoide de activación se obtienen peores resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Continúen experimentando con las funciones de activación.  Intenten aplicar un ReLu a la primera capa escondida y tanh a la segunda.  La activación tanh se obtiene escribiendo “tanh”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 50\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='tanh'), # 2nda capa escondida\n",
    "\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 2s - loss: 0.3971 - accuracy: 0.8910 - val_loss: 0.1871 - val_accuracy: 0.9470 - 2s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 1s - loss: 0.1617 - accuracy: 0.9524 - val_loss: 0.1278 - val_accuracy: 0.9640 - 1s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 1s - loss: 0.1180 - accuracy: 0.9654 - val_loss: 0.1033 - val_accuracy: 0.9700 - 1s/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 1s - loss: 0.0929 - accuracy: 0.9725 - val_loss: 0.0816 - val_accuracy: 0.9745 - 1s/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 1s - loss: 0.0772 - accuracy: 0.9765 - val_loss: 0.0709 - val_accuracy: 0.9795 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d6112c06d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "modelo.fit(datos_entreno, \n",
    "          epochs = 5, \n",
    "          validation_data = (entradas_validacion, metas_validacion),\n",
    "          validation_steps = 10,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0908 - accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida de prueba: 0.09. Precisión de prueba: 97.18%\n"
     ]
    }
   ],
   "source": [
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_prueba * 100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "347a625715fe29511df74443d0ac60b514ce17bf8af058876f43cde387af9535"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
